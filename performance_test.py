# -*- coding: utf-8 -*-
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬
ç”¨äºè¯„ä¼°Vercelç¯å¢ƒä¸‹çš„åº”ç”¨æ€§èƒ½
"""

import time
import requests
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed

def test_endpoint_performance(url, endpoint, num_requests=10):
    """æµ‹è¯•å•ä¸ªç«¯ç‚¹çš„æ€§èƒ½"""
    times = []
    errors = 0
    
    print(f"æµ‹è¯•ç«¯ç‚¹: {endpoint}")
    
    for i in range(num_requests):
        try:
            start_time = time.time()
            response = requests.get(f"{url}{endpoint}", timeout=30)
            end_time = time.time()
            
            if response.status_code == 200:
                times.append(end_time - start_time)
                print(f"  è¯·æ±‚ {i+1}: {times[-1]:.3f}ç§’")
            else:
                errors += 1
                print(f"  è¯·æ±‚ {i+1}: é”™è¯¯çŠ¶æ€ç  {response.status_code}")
                
        except Exception as e:
            errors += 1
            print(f"  è¯·æ±‚ {i+1}: é”™è¯¯ - {e}")
    
    if times:
        avg_time = statistics.mean(times)
        min_time = min(times)
        max_time = max(times)
        print(f"  âœ… å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}ç§’")
        print(f"  ğŸ“Š æœ€å¿«: {min_time:.3f}ç§’, æœ€æ…¢: {max_time:.3f}ç§’")
        print(f"  âŒ é”™è¯¯æ•°: {errors}")
        return {
            'endpoint': endpoint,
            'avg_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'errors': errors,
            'success_rate': (num_requests - errors) / num_requests * 100
        }
    else:
        print(f"  âŒ æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†")
        return None

def test_concurrent_performance(url, endpoint, num_concurrent=5, requests_per_thread=2):
    """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
    print(f"\næµ‹è¯•å¹¶å‘æ€§èƒ½: {endpoint} ({num_concurrent} å¹¶å‘, æ¯ä¸ªçº¿ç¨‹ {requests_per_thread} è¯·æ±‚)")
    
    def worker():
        return test_endpoint_performance(url, endpoint, requests_per_thread)
    
    start_time = time.time()
    with ThreadPoolExecutor(max_workers=num_concurrent) as executor:
        futures = [executor.submit(worker) for _ in range(num_concurrent)]
        results = []
        for future in as_completed(futures):
            result = future.result()
            if result:
                results.append(result)
    
    end_time = time.time()
    total_time = end_time - start_time
    
    if results:
        avg_response_times = [r['avg_time'] for r in results]
        total_avg = statistics.mean(avg_response_times)
        print(f"  ğŸ“ˆ å¹¶å‘æµ‹è¯•å®Œæˆ: {total_time:.3f}ç§’")
        print(f"  ğŸ¯ å¹³å‡å“åº”æ—¶é—´: {total_avg:.3f}ç§’")
        print(f"  ğŸ“Š ååé‡: {num_concurrent * requests_per_thread / total_time:.2f} è¯·æ±‚/ç§’")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # æµ‹è¯•URLï¼ˆè¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…URLï¼‰
    test_urls = [
        "https://interest-based-translation-platform.vercel.app",
        "https://interest-based-translation-pla-git-3679f1-yang-xingyus-projects.vercel.app"
    ]
    
    # æµ‹è¯•ç«¯ç‚¹
    endpoints = [
        "/",
        "/works",
        "/profile",
        "/static/favicon.ico"
    ]
    
    for url in test_urls:
        print(f"\n{'='*60}")
        print(f"æµ‹è¯•URL: {url}")
        print(f"{'='*60}")
        
        # å•çº¿ç¨‹æµ‹è¯•
        for endpoint in endpoints:
            test_endpoint_performance(url, endpoint, num_requests=5)
        
        # å¹¶å‘æµ‹è¯•
        test_concurrent_performance(url, "/", num_concurrent=3, requests_per_thread=2)

if __name__ == '__main__':
    main()
